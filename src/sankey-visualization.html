<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Datasets Flow Visualization</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/7.8.5/d3.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/d3-sankey/0.12.3/d3-sankey.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lodash.js/4.17.21/lodash.min.js"></script>
    <style>
        body {
            font-family: 'Arial', sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1600px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }
        
        h1 {
            color: #333;
            text-align: center;
            margin-bottom: 10px;
            font-size: 2.5em;
        }
        
        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.2em;
        }
        
        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin-bottom: 30px;
            flex-wrap: wrap;
        }
        
        .control-group {
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        label {
            margin-bottom: 5px;
            color: #555;
            font-weight: bold;
        }
        
        select, button {
            padding: 10px 15px;
            border-radius: 8px;
            border: 2px solid #ddd;
            font-size: 14px;
            cursor: pointer;
            transition: all 0.3s ease;
        }
        
        select:hover, button:hover {
            border-color: #667eea;
            box-shadow: 0 2px 8px rgba(102, 126, 234, 0.2);
        }
        
        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            font-weight: bold;
            padding: 12px 25px;
        }
        
        button:active {
            transform: scale(0.98);
        }
        
        #chart {
            background: #fafafa;
            border-radius: 10px;
            padding: 20px;
            min-height: 600px;
        }
        
        .node rect {
            cursor: pointer;
            fill-opacity: .9;
            shape-rendering: crispEdges;
        }
        
        .node text {
            pointer-events: none;
            font-size: 12px;
            font-weight: 500;
        }
        
        .link {
            fill: none;
            stroke-opacity: 0.5;
            transition: stroke-opacity 0.3s;
        }
        
        .link:hover {
            stroke-opacity: 0.8;
        }
        
        .tooltip {
            position: absolute;
            text-align: center;
            padding: 10px;
            font-size: 12px;
            background: rgba(0, 0, 0, 0.8);
            color: white;
            border-radius: 5px;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.3s;
        }
        
        .legend {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
            margin-top: 20px;
            padding: 15px;
            background: #f5f5f5;
            border-radius: 10px;
        }
        
        .legend-item {
            display: flex;
            align-items: center;
            gap: 5px;
        }
        
        .legend-color {
            width: 20px;
            height: 20px;
            border-radius: 3px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽµ Audio Datasets Flow Visualization</h1>
        <div class="subtitle">Interactive Sankey Diagram: Dataset â†’ Contents â†’ Source â†’ Use Case</div>
        
        <div class="controls">
            <div class="control-group">
                <label for="viewSelect">Select View:</label>
                <select id="viewSelect">
                    <option value="contents-source-usecase">Contents â†’ Source â†’ Use Case</option>
                    <option value="dataset-contents-source-usecase">Dataset â†’ Contents â†’ Source â†’ Use Case</option>
                </select>
            </div>
            
            <div class="control-group">
                <label for="filterContent">Filter by Content:</label>
                <select id="filterContent">
                    <option value="all">All Contents</option>
                    <option value="audio clips">Audio Clips</option>
                    <option value="short video clips">Short Video Clips</option>
                    <option value="audibooks">Audiobooks</option>
                    <option value="music tracks">Music Tracks</option>
                </select>
            </div>
            
            <div class="control-group">
                <button onclick="resetFilters()">Reset All Filters</button>
            </div>
        </div>
        
        <div id="chart"></div>
        <div class="tooltip"></div>
        
        <div class="legend" id="legend"></div>
    </div>

    <script>
        // Embedded data based on the CSV analysis
        const embeddedData = [
            // AudioSet
            {dataset: "AudioSet", contents: "short video clips", source: "Youtube", usecase: "Audio classification"},
            // VGG-Sound
            {dataset: "VGG-Sound", contents: "short video clips", source: "Youtube", usecase: "Audio classification"},
            // VoxCeleb1
            {dataset: "VoxCeleb1", contents: "short video clips", source: "Youtube", usecase: "Audio classification"},
            // Kinetics-700
            {dataset: "Kinetics-700", contents: "short video clips", source: "Youtube", usecase: "Audio classification"},
            // MELD
            {dataset: "MELD", contents: "short video clips", source: "TV show", usecase: "Audio classification"},
            
            // AudioCaps
            {dataset: "AudioCaps", contents: "audio clips", source: "Subset", usecase: "Audio captioning"},
            // MACS
            {dataset: "MACS", contents: "audio clips", source: "Subset", usecase: "Audio captioning"},
            {dataset: "MACS (Multi-Annotator Captioned Soundscapes)", contents: "audio clips", source: "Subset", usecase: "Audio captioning"},
            // WavCaps
            {dataset: "WavCaps", contents: "audio clips", source: "Freesound.org", usecase: "Audio captioning"},
            // Clotho
            {dataset: "Clotho", contents: "audio clips", source: "Freesound.org", usecase: "Audio captioning"},
            
            // AVSpeech
            {dataset: "AVSpeech", contents: "short video clips", source: "Youtube", usecase: "Automatic speech recognition"},
            {dataset: "AVSpeech", contents: "short video clips", source: "TED Talks", usecase: "Automatic speech recognition"},
            
            // UrbanSound8K
            {dataset: "UrbanSound8K", contents: "audio clips", source: "Freesound.org", usecase: "Audio classification"},
            // ESC-50
            {dataset: "ESC-50", contents: "audio clips", source: "Freesound.org", usecase: "Audio classification"},
            // FSD50K
            {dataset: "FSD50K", contents: "audio clips", source: "Freesound.org", usecase: "Audio classification"},
            
            // Recording-based datasets
            {dataset: "ICBHI Respiratory Sound Database", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "SHD (Spiking Heidelberg Digits)", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "TAU2020", contents: "audio clips", source: "Public area recordings", usecase: "Audio classification"},
            {dataset: "TUT Sound Events 2017", contents: "audio clips", source: "Public area recordings", usecase: "Audio classification"},
            {dataset: "EmoDB Dataset (Berlin Database of Emotional Speech)", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "SEP-28k", contents: "audio clips", source: "Podcasts", usecase: "Audio classification"},
            {dataset: "EPIC-SOUNDS (EPIC-KITCHENS-100)", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "MINDS-14", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "BGG (PUBG Gun Sound Dataset)", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "FLEURS", contents: "audio clips", source: "Wikipedia", usecase: "Audio classification"},
            {dataset: "DiCOVA", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "IEMOCAP", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "Coswara Dataset", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "COUGHVID", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "Cat Meow", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "CochlScene", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "SONYC-UST-V2", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "Free Spoken Digit Dataset (FSDD)", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "AudioMNIST", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "AFRODIGITS", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "SpokeN-100", contents: "audio clips", source: "Personal recordings", usecase: "Audio classification"},
            {dataset: "ISOLET", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "Nonspeech7k", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "aGender", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "VocalSound", contents: "audio clips", source: "Crowdsourcing", usecase: "Audio classification"},
            {dataset: "MAD", contents: "audio clips", source: "Podcasts", usecase: "Audio classification"},
            {dataset: "Mivia Audio Events", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "Hey Snapdragon Keyword Dataset", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "Hey Snips", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            
            // Speech recognition datasets
            {dataset: "LibriSpeech", contents: "audibooks", source: "LibriVox.com", usecase: "Automatic speech recognition"},
            {dataset: "Common Voice", contents: "audio clips", source: "Crowdsourcing", usecase: "Automatic speech recognition"},
            {dataset: "Speech Commands", contents: "audio clips", source: "Unknown", usecase: "Audio classification"},
            {dataset: "Switchboard-1 Corpus", contents: "audio clips", source: "Recoding", usecase: "Automatic speech recognition"},
            {dataset: "WSJ0-2mix", contents: "audio clips", source: "Recoding", usecase: "Automatic speech recognition"},
            {dataset: "DEMAND", contents: "audio clips", source: "Recoding", usecase: "Automatic speech recognition"},
            {dataset: "Wham!", contents: "audio clips", source: "Recoding", usecase: "Automatic speech recognition"},
            
            // Music datasets
            {dataset: "GTZAN", contents: "music tracks", source: "Personal recordings", usecase: "Music research task"},
            {dataset: "MagnaTagATune", contents: "music tracks", source: "Unknown", usecase: "Music research task"},
            {dataset: "MusicNet", contents: "music tracks", source: "Public archive", usecase: "Music research task"},
            {dataset: "RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)", contents: "audio clips", source: "Recoding", usecase: "Audio classification"},
            {dataset: "OpenMIC-2018", contents: "music tracks", source: "Free Music Archive (FMA)", usecase: "Music research task"},
            {dataset: "Hey Guile", contents: "music tracks", source: "Personal recordings", usecase: "Music research task"},
            {dataset: "MUSDB18", contents: "music tracks", source: "Free Music Archive (FMA)", usecase: "Music research task"},
            
            // Sound effects
            {dataset: "BigSoundBank", contents: "audio clips", source: "BigSoundBank 2", usecase: "Audio classification"},
            {dataset: "SoundBible", contents: "audio clips", source: "SoundBible", usecase: "Audio classification"},
            {dataset: "BBC Sound Effects", contents: "audio clips", source: "BBC Sound Effects", usecase: "Audio classification"},
            
            // Special datasets
            {dataset: "DEEP-VOICE: DeepFake Voice Recognition (Jordan Bird)", contents: "audio clips", source: "Unknown", usecase: "Audio classification"},
            {dataset: "BirdCLEF2023", contents: "audio clips", source: "Recoding", usecase: "Bioacoustics analysis"},
            {dataset: "Text prompts", contents: "audio clips", source: "Artificially generated (text prompts)", usecase: "Audio classification"},
            {dataset: "MedleyDB", contents: "music tracks", source: "MedleyDB", usecase: "Music research task"}
        ];
        
        let allData = embeddedData.map(d => ({...d, value: 1}));
        let currentView = 'contents-source-usecase';
        let contentFilter = 'all';
        
        // Color schemes for different node types
        const colors = {
            datasets: d3.scaleOrdinal(d3.schemeSet3),
            contents: {
                'audio clips': '#8dd3c7',
                'short video clips': '#80b1d3',
                'audibooks': '#bebada',
                'music tracks': '#fb8072',
                'Unknown': '#ccc'
            },
            sources: {
                'Youtube': '#ff7f0e',
                'Recoding': '#2ca02c',
                'Crowdsourcing': '#d62728',
                'Freesound.org': '#9467bd',
                'Public area recordings': '#8c564b',
                'Wikipedia': '#e377c2',
                'Podcasts': '#7f7f7f',
                'Subset': '#bcbd22',
                'TED Talks': '#17becf',
                'LibriVox.com': '#aec7e8',
                'BBC Sound Effects': '#ffbb78',
                'Free Music Archive (FMA)': '#98df8a',
                'TV show': '#ff9896',
                'MedleyDB': '#c5b0d5',
                'Artificially generated (text prompts)': '#c49c94',
                'Public archive': '#f7b6d2',
                'Personal recordings': '#c7c7c7',
                'BigSoundBank 2': '#dbdb8d',
                'SoundBible': '#9edae5',
                'Unknown': '#ccc'
            },
            usecases: {
                'Audio classification': '#1f77b4',
                'Audio captioning': '#ff7f0e',
                'Automatic speech recognition': '#2ca02c',
                'Music research task': '#d62728',
                'Bioacoustics analysis': '#9467bd',
                'Unknown': '#ccc'
            }
        };

        function updateVisualization() {
            const viewSelect = document.getElementById('viewSelect');
            currentView = viewSelect.value;
            
            const contentSelect = document.getElementById('filterContent');
            contentFilter = contentSelect.value;
            
            // Filter data
            let filteredData = allData;
            if (contentFilter !== 'all') {
                filteredData = filteredData.filter(d => d.contents === contentFilter);
            }
            
            if (currentView === 'contents-source-usecase') {
                renderAggregatedSankey(filteredData);
            } else {
                renderDetailedSankey(filteredData);
            }
            
            updateLegend();
        }

        function renderAggregatedSankey(data) {
            // Clear previous chart
            d3.select('#chart').selectAll('*').remove();
            
            if (data.length === 0) {
                d3.select('#chart').append('p')
                    .style('text-align', 'center')
                    .style('color', '#666')
                    .text('No data available for the selected filters');
                return;
            }
            
            // Aggregate data
            const aggregated = d3.rollup(
                data,
                v => v.length,
                d => d.contents,
                d => d.source,
                d => d.usecase
            );
            
            // Create nodes and links
            const nodes = [];
            const links = [];
            const nodeMap = new Map();
            let nodeId = 0;
            
            // Add nodes for each level
            const contents = new Set();
            const sources = new Set();
            const usecases = new Set();
            
            aggregated.forEach((sourceMap, content) => {
                contents.add(content);
                sourceMap.forEach((usecaseMap, source) => {
                    sources.add(source);
                    usecaseMap.forEach((value, usecase) => {
                        usecases.add(usecase);
                    });
                });
            });
            
            // Create nodes
            contents.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'contents' });
                nodeMap.set(`contents:${name}`, id);
            });
            
            sources.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'source' });
                nodeMap.set(`source:${name}`, id);
            });
            
            usecases.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'usecase' });
                nodeMap.set(`usecase:${name}`, id);
            });
            
            // Create links
            aggregated.forEach((sourceMap, content) => {
                sourceMap.forEach((usecaseMap, source) => {
                    const contentSourceValue = d3.sum(usecaseMap.values());
                    links.push({
                        source: nodeMap.get(`contents:${content}`),
                        target: nodeMap.get(`source:${source}`),
                        value: contentSourceValue
                    });
                    
                    usecaseMap.forEach((value, usecase) => {
                        links.push({
                            source: nodeMap.get(`source:${source}`),
                            target: nodeMap.get(`usecase:${usecase}`),
                            value: value
                        });
                    });
                });
            });
            
            drawSankey(nodes, links);
        }

        function renderDetailedSankey(data) {
            // Clear previous chart
            d3.select('#chart').selectAll('*').remove();
            
            if (data.length === 0) {
                d3.select('#chart').append('p')
                    .style('text-align', 'center')
                    .style('color', '#666')
                    .text('No data available for the selected filters');
                return;
            }
            
            // Create nodes and links
            const nodes = [];
            const links = [];
            const nodeMap = new Map();
            let nodeId = 0;
            
            // Get unique values for each level
            const datasets = new Set();
            const contents = new Set();
            const sources = new Set();
            const usecases = new Set();
            
            data.forEach(d => {
                datasets.add(d.dataset);
                contents.add(d.contents);
                sources.add(d.source);
                usecases.add(d.usecase);
            });
            
            // Create nodes
            datasets.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'dataset' });
                nodeMap.set(`dataset:${name}`, id);
            });
            
            contents.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'contents' });
                nodeMap.set(`contents:${name}`, id);
            });
            
            sources.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'source' });
                nodeMap.set(`source:${name}`, id);
            });
            
            usecases.forEach(name => {
                const id = nodeId++;
                nodes.push({ id, name, type: 'usecase' });
                nodeMap.set(`usecase:${name}`, id);
            });
            
            // Aggregate links
            const linkMap = new Map();
            
            data.forEach(d => {
                // Dataset to Contents
                const key1 = `${d.dataset}|${d.contents}`;
                if (!linkMap.has(key1)) {
                    linkMap.set(key1, {
                        source: nodeMap.get(`dataset:${d.dataset}`),
                        target: nodeMap.get(`contents:${d.contents}`),
                        value: 0
                    });
                }
                linkMap.get(key1).value += d.value;
                
                // Contents to Source
                const key2 = `${d.contents}|${d.source}`;
                if (!linkMap.has(key2)) {
                    linkMap.set(key2, {
                        source: nodeMap.get(`contents:${d.contents}`),
                        target: nodeMap.get(`source:${d.source}`),
                        value: 0
                    });
                }
                linkMap.get(key2).value += d.value;
                
                // Source to Usecase
                const key3 = `${d.source}|${d.usecase}`;
                if (!linkMap.has(key3)) {
                    linkMap.set(key3, {
                        source: nodeMap.get(`source:${d.source}`),
                        target: nodeMap.get(`usecase:${d.usecase}`),
                        value: 0
                    });
                }
                linkMap.get(key3).value += d.value;
            });
            
            const linksArray = Array.from(linkMap.values());
            
            drawSankey(nodes, linksArray);
        }

        function drawSankey(nodes, links) {
            const margin = { top: 20, right: 150, bottom: 20, left: 150 };
            const width = 1240 - margin.left - margin.right;
            const height = Math.max(600, nodes.length * 15);
            
            const svg = d3.select('#chart')
                .append('svg')
                .attr('width', width + margin.left + margin.right)
                .attr('height', height + margin.top + margin.bottom)
                .append('g')
                .attr('transform', `translate(${margin.left},${margin.top})`);
            
            const sankey = d3.sankey()
                .nodeId(d => d.id)
                .nodeWidth(20)
                .nodePadding(15)
                .extent([[0, 0], [width, height]]);
            
            const graph = sankey({
                nodes: nodes.map(d => Object.assign({}, d)),
                links: links.map(d => Object.assign({}, d))
            });
            
            // Create tooltip
            const tooltip = d3.select('.tooltip');
            
            // Draw links
            const link = svg.append('g')
                .selectAll('.link')
                .data(graph.links)
                .enter().append('path')
                .attr('class', 'link')
                .attr('d', d3.sankeyLinkHorizontal())
                .style('stroke', d => {
                    const sourceType = d.source.type;
                    if (sourceType === 'dataset') return colors.datasets(d.source.name);
                    if (sourceType === 'contents') return colors.contents[d.source.name] || '#ccc';
                    if (sourceType === 'source') return colors.sources[d.source.name] || '#ccc';
                    return '#ccc';
                })
                .style('stroke-width', d => Math.max(1, d.width))
                .on('mouseover', function(event, d) {
                    tooltip.transition().duration(200).style('opacity', .9);
                    tooltip.html(`${d.source.name} â†’ ${d.target.name}<br>Count: ${d.value}`)
                        .style('left', (event.pageX + 10) + 'px')
                        .style('top', (event.pageY - 28) + 'px');
                })
                .on('mouseout', function(d) {
                    tooltip.transition().duration(500).style('opacity', 0);
                });
            
            // Draw nodes
            const node = svg.append('g')
                .selectAll('.node')
                .data(graph.nodes)
                .enter().append('g')
                .attr('class', 'node')
                .attr('transform', d => `translate(${d.x0},${d.y0})`);
            
            node.append('rect')
                .attr('height', d => d.y1 - d.y0)
                .attr('width', sankey.nodeWidth())
                .style('fill', d => {
                    if (d.type === 'dataset') return colors.datasets(d.name);
                    if (d.type === 'contents') return colors.contents[d.name] || '#ccc';
                    if (d.type === 'source') return colors.sources[d.name] || '#ccc';
                    if (d.type === 'usecase') return colors.usecases[d.name] || '#ccc';
                    return '#ccc';
                })
                .on('mouseover', function(event, d) {
                    tooltip.transition().duration(200).style('opacity', .9);
                    tooltip.html(`<strong>${d.name}</strong><br>Total: ${d.value}`)
                        .style('left', (event.pageX + 10) + 'px')
                        .style('top', (event.pageY - 28) + 'px');
                })
                .on('mouseout', function(d) {
                    tooltip.transition().duration(500).style('opacity', 0);
                });
            
            // Add labels
            node.append('text')
                .attr('x', d => d.x0 < width / 2 ? -6 : sankey.nodeWidth() + 6)
                .attr('y', d => (d.y1 - d.y0) / 2)
                .attr('dy', '0.35em')
                .attr('text-anchor', d => d.x0 < width / 2 ? 'end' : 'start')
                .text(d => d.name)
                .style('fill', '#333')
                .style('font-size', d => {
                    const height = d.y1 - d.y0;
                    if (height < 20) return '10px';
                    if (height < 30) return '11px';
                    return '12px';
                });
        }

        function updateLegend() {
            const legend = document.getElementById('legend');
            legend.innerHTML = '';
            
            // Add legend based on current view
            const legendData = [];
            
            if (currentView === 'contents-source-usecase') {
                // Contents legend
                Object.entries(colors.contents).forEach(([key, color]) => {
                    if (key !== 'Unknown' && allData.some(d => d.contents === key)) {
                        legendData.push({ name: `Contents: ${key}`, color });
                    }
                });
            }
            
            // Always show usecase legend
            Object.entries(colors.usecases).forEach(([key, color]) => {
                if (key !== 'Unknown' && allData.some(d => d.usecase === key)) {
                    legendData.push({ name: `Use Case: ${key}`, color });
                }
            });
            
            legendData.forEach(item => {
                const div = document.createElement('div');
                div.className = 'legend-item';
                div.innerHTML = `
                    <div class="legend-color" style="background: ${item.color};"></div>
                    <span>${item.name}</span>
                `;
                legend.appendChild(div);
            });
        }

        function resetFilters() {
            document.getElementById('viewSelect').value = 'contents-source-usecase';
            document.getElementById('filterContent').value = 'all';
            updateVisualization();
        }

        // Event listeners
        document.getElementById('viewSelect').addEventListener('change', updateVisualization);
        document.getElementById('filterContent').addEventListener('change', updateVisualization);

        // Initialize
        updateVisualization();
    </script>
</body>
</html>